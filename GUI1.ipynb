{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a04fae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56t\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Bhanu Srinija\\AppData\\Local\\Temp\\ipykernel_3700\\1508973350.py\", line 208, in <lambda>\n",
      "    Display = tk.Button(self, height = 2,width = 20,text =\"Convert\",command = lambda:Take_input(inputtxt), bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
      "                                                                                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Bhanu Srinija\\AppData\\Local\\Temp\\ipykernel_3700\\1508973350.py\", line 197, in Take_input\n",
      "    gif_frames=func(INPUT)\n",
      "               ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Bhanu Srinija\\AppData\\Local\\Temp\\ipykernel_3700\\1508973350.py\", line 71, in func\n",
      "    im = PIL.Image.open(alpha_dest + str(j).lower() + \"_small.gif\")\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py\", line 3247, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Bhanu Srinija\\\\AD Sign language\\\\alphabet\\\\\\\\5_small.gif'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "h\n",
      "i\n",
      "hello\n",
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      "hello\n",
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      "windy\n",
      "windy.webp\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "import PIL.Image\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from itertools import count\n",
    "import string\n",
    "from tkinter import *\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import Tkinter as tk\n",
    "except:\n",
    "    import tkinter as tk\n",
    "\n",
    "image_x, image_y = 64, 64\n",
    "from keras.models import load_model\n",
    "\n",
    "# classifier = load_model('asl_detection.h5')\n",
    "\n",
    "def give_char():\n",
    "    import numpy as np\n",
    "    from keras.preprocessing import image\n",
    "    test_image = image.load_img('tmp1.png', target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = classifier.predict(test_image)\n",
    "    print(result)\n",
    "    chars = \"ABCDEFGHIJKMNOPQRSTUVWXYZ\"\n",
    "    indx = np.argmax(result[0])\n",
    "    print(indx)\n",
    "    return (chars[indx])\n",
    "\n",
    "\n",
    "def check_sim(i, file_map):\n",
    "    for item in file_map:\n",
    "        for word in file_map[item]:\n",
    "            if (i == word):\n",
    "                return 1, item\n",
    "    return -1, \"\"\n",
    "\n",
    "\n",
    "op_dest = r\"C:\\Users\\Bhanu Srinija\\AD Sign language\\filtered_data\\\\\"\n",
    "alpha_dest = r\"C:\\Users\\Bhanu Srinija\\AD Sign language\\alphabet\\\\\"\n",
    "dirListing = os.listdir(op_dest)\n",
    "editFiles = []\n",
    "for item in dirListing:\n",
    "    if \".webp\" in item:\n",
    "        editFiles.append(item)\n",
    "\n",
    "file_map = {}\n",
    "for i in editFiles:\n",
    "    tmp = i.replace(\".webp\", \"\")\n",
    "    tmp = tmp.split()\n",
    "    file_map[i] = tmp\n",
    "\n",
    "\n",
    "def func(a):\n",
    "    all_frames = []\n",
    "    final = PIL.Image.new('RGB', (380, 260))\n",
    "    words = a.split()\n",
    "    for i in words:\n",
    "        flag, sim = check_sim(i, file_map)\n",
    "        if (flag == -1):\n",
    "            for j in i:\n",
    "                print(j)\n",
    "                speak_output(j)\n",
    "                im = PIL.Image.open(alpha_dest + str(j).lower() + \"_small.gif\")\n",
    "                frameCnt = im.n_frames\n",
    "                for frame_cnt in range(frameCnt):\n",
    "                    im.seek(frame_cnt)\n",
    "                    im.save(\"tmp.png\")\n",
    "                    img = cv2.imread(\"tmp.png\")\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (380, 260))\n",
    "                    im_arr = PIL.Image.fromarray(img)\n",
    "                    for itr in range(15):\n",
    "                        all_frames.append(im_arr)\n",
    "        else:\n",
    "            print(sim)\n",
    "            speak_output(sim)\n",
    "            im = PIL.Image.open(op_dest + sim)\n",
    "            im.info.pop('background', None)\n",
    "            im.save('tmp.gif', 'gif', save_all=True)\n",
    "            im = PIL.Image.open(\"tmp.gif\")\n",
    "            frameCnt = im.n_frames\n",
    "            for frame_cnt in range(frameCnt):\n",
    "                im.seek(frame_cnt)\n",
    "                im.save(\"tmp.png\")\n",
    "                img = cv2.imread(\"tmp.png\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (380, 260))\n",
    "                im_arr = PIL.Image.fromarray(img)\n",
    "                all_frames.append(im_arr)\n",
    "                all_frames.append(im_arr)  # Add an additional frame to add pause after each symbol\n",
    "    final.save(\"out.gif\", save_all=True, append_images=all_frames, duration=100, loop=0)\n",
    "    return all_frames\n",
    "\n",
    "\n",
    "def speak_output(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "img_counter = 0\n",
    "img_text = ''\n",
    "\n",
    "\n",
    "class Tk_Manage(tk.Tk):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "        container = tk.Frame(self)\n",
    "        container.pack(side=\"top\", fill=\"both\", expand=True)\n",
    "        container.grid_rowconfigure(0, weight=1)\n",
    "        container.grid_columnconfigure(0, weight=1)\n",
    "        self.frames = {}\n",
    "        for F in (StartPage, VtoS):\n",
    "            frame = F(container, self)\n",
    "            self.frames[F] = frame\n",
    "            frame.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        self.show_frame(StartPage)\n",
    "\n",
    "    def show_frame(self, cont):\n",
    "        frame = self.frames[cont]\n",
    "        frame.tkraise()\n",
    "\n",
    "\n",
    "class StartPage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        # Load background image\n",
    "        self.background_image = PIL.Image.open(r\"C:\\Users\\Bhanu Srinija\\AD Sign language\\a5.jpg\")\n",
    "        self.background_photo = ImageTk.PhotoImage(self.background_image)\n",
    "        self.background_label = tk.Label(self, image=self.background_photo)\n",
    "        self.background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "        label = tk.Label(self, text=\"Sign Language Translator\", font=(\"Verdana\", 12))\n",
    "        label.pack(pady=10, padx=10)\n",
    "        button_text_to_sign = tk.Button(self, text=\"Text to Sign\", command=lambda: controller.show_frame(VtoS), bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
    "        button_text_to_sign.pack()\n",
    "\n",
    "        # New button for camera detection\n",
    "        button_camera_detection = tk.Button(self, text=\"Camera Detection\", command=self.start_camera_detection, bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
    "        button_camera_detection.pack()\n",
    "\n",
    "    def start_camera_detection(self):\n",
    "        # Execute the code from test.py for camera detection\n",
    "        exec(open(\"test.py\").read())\n",
    "\n",
    "\n",
    "# VtoS class\n",
    "class VtoS(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        cnt=0\n",
    "        gif_frames=[]\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        label = tk.Label(self, text=\"Text to Sign\", font=(\"Verdana\", 12))\n",
    "        label.pack(pady=10,padx=10)\n",
    "        gif_box = tk.Label(self)\n",
    "        \n",
    "        button1 = tk.Button(self, text=\"Back to Home\",command=lambda: controller.show_frame(StartPage), bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
    "        button1.pack()\n",
    "        \n",
    "        def gif_stream():\n",
    "            global cnt\n",
    "            global gif_frames\n",
    "            if(cnt==len(gif_frames)):\n",
    "                return\n",
    "            img = gif_frames[cnt]\n",
    "            cnt+=1\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            gif_box.imgtk = imgtk\n",
    "            gif_box.configure(image=imgtk)\n",
    "            gif_box.after(50, gif_stream)\n",
    "        \n",
    "        def hear_voice(inputtxt):\n",
    "            store = sr.Recognizer()\n",
    "            with sr.Microphone() as s:\n",
    "                audio_input = store.record(s, duration=10)\n",
    "                try:\n",
    "                    text_output = store.recognize_google(audio_input)\n",
    "                    inputtxt.insert(END, text_output)\n",
    "                    # Automatically convert to sign language after voice detection\n",
    "                    Take_input(inputtxt)\n",
    "                except:\n",
    "                    print(\"Error Hearing Voice\")\n",
    "                    inputtxt.insert(END, '')\n",
    "                    \n",
    "        def Take_input(inputtxt):\n",
    "            INPUT = inputtxt.get(\"1.0\", \"end-1c\")\n",
    "            print(INPUT)\n",
    "            global gif_frames\n",
    "            gif_frames=func(INPUT)\n",
    "            global cnt\n",
    "            cnt=0\n",
    "            gif_stream()\n",
    "            gif_box.place(x=400,y=160)\n",
    "        \n",
    "        l = tk.Label(self,text = \"Enter Text or Voice:\")\n",
    "        l1 = tk.Label(self,text = \"OR\")\n",
    "        inputtxt = tk.Text(self, height = 4,width = 25)\n",
    "        voice_button= tk.Button(self,height = 2,width = 20, text=\"Record Voice\",command=lambda: hear_voice(inputtxt), bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
    "        voice_button.place(x=50,y=180)\n",
    "        Display = tk.Button(self, height = 2,width = 20,text =\"Convert\",command = lambda:Take_input(inputtxt), bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
    "        l.place(x=50, y=160)\n",
    "        l1.place(x=115, y=230)\n",
    "        inputtxt.place(x=50, y=250)\n",
    "        Display.pack()\n",
    "\n",
    "app = Tk_Manage()\n",
    "app.geometry(\"900x500\")\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762e09b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
