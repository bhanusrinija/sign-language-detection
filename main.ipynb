{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78cecf99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windy\n",
      "windy.webp\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "import PIL.Image\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from itertools import count\n",
    "import string\n",
    "from tkinter import *\n",
    "import time\n",
    "try:\n",
    "    import Tkinter as tk\n",
    "except:\n",
    "    import tkinter as tk\n",
    "import numpy as np\n",
    "image_x, image_y = 64,64\n",
    "from keras.models import load_model\n",
    "\n",
    "#classifier = load_model('asl_detection.h5')\n",
    "\n",
    "def give_char():\n",
    "    import numpy as np\n",
    "    from keras.preprocessing import image\n",
    "    test_image = image.load_img('tmp1.png', target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "    print(result)\n",
    "    chars=\"ABCDEFGHIJKMNOPQRSTUVWXYZ\"\n",
    "    indx=  np.argmax(result[0])\n",
    "    print(indx)\n",
    "    return(chars[indx])\n",
    "\n",
    "def check_sim(i,file_map):\n",
    "    for item in file_map:\n",
    "        for word in file_map[item]:\n",
    "            if(i==word):\n",
    "                return 1,item\n",
    "    return -1,\"\"\n",
    "\n",
    "op_dest = r\"C:\\Users\\Bhanu Srinija\\AD Sign language\\filtered_data\\\\\"\n",
    "alpha_dest = r\"C:\\Users\\Bhanu Srinija\\AD Sign language\\alphabet\\\\\"\n",
    "dirListing = os.listdir(op_dest)\n",
    "editFiles = []\n",
    "for item in dirListing:\n",
    "    if \".webp\" in item:\n",
    "        editFiles.append(item)\n",
    "\n",
    "file_map={}\n",
    "for i in editFiles:\n",
    "    tmp=i.replace(\".webp\",\"\")\n",
    "    tmp=tmp.split()\n",
    "    file_map[i]=tmp\n",
    "\n",
    "def func(a):\n",
    "    all_frames=[]\n",
    "    final= PIL.Image.new('RGB', (380, 260))\n",
    "    words=a.split()\n",
    "    for i in words:\n",
    "        flag,sim=check_sim(i,file_map)\n",
    "        if(flag==-1):\n",
    "            for j in i:\n",
    "                print(j)\n",
    "                speak_output(j)\n",
    "                im = PIL.Image.open(alpha_dest+str(j).lower()+\"_small.gif\")\n",
    "                frameCnt = im.n_frames\n",
    "                for frame_cnt in range(frameCnt):\n",
    "                    im.seek(frame_cnt)\n",
    "                    im.save(\"tmp.png\")\n",
    "                    img = cv2.imread(\"tmp.png\")\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (380,260))\n",
    "                    im_arr = PIL.Image.fromarray(img)\n",
    "                    for itr in range(15):\n",
    "                        all_frames.append(im_arr)\n",
    "        else:\n",
    "            print(sim)\n",
    "            speak_output(sim)\n",
    "            im = PIL.Image.open(op_dest+sim)\n",
    "            im.info.pop('background', None)\n",
    "            im.save('tmp.gif', 'gif', save_all=True)\n",
    "            im = PIL.Image.open(\"tmp.gif\")\n",
    "            frameCnt = im.n_frames\n",
    "            for frame_cnt in range(frameCnt):\n",
    "                im.seek(frame_cnt)\n",
    "                im.save(\"tmp.png\")\n",
    "                img = cv2.imread(\"tmp.png\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (380,260))\n",
    "                im_arr = PIL.Image.fromarray(img)\n",
    "                all_frames.append(im_arr)\n",
    "                all_frames.append(im_arr)  # Add an additional frame to add pause after each symbol\n",
    "    final.save(\"out.gif\", save_all=True, append_images=all_frames, duration=100, loop=0)\n",
    "    return all_frames \n",
    "\n",
    "def speak_output(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "img_counter = 0\n",
    "img_text=''\n",
    "\n",
    "class Tk_Manage(tk.Tk):\n",
    "    def __init__(self, *args, **kwargs):     \n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "        container = tk.Frame(self)\n",
    "        container.pack(side=\"top\", fill=\"both\", expand = True)\n",
    "        container.grid_rowconfigure(0, weight=1)\n",
    "        container.grid_columnconfigure(0, weight=1)\n",
    "        self.frames = {}\n",
    "        for F in (StartPage, VtoS):\n",
    "            frame = F(container, self)\n",
    "            self.frames[F] = frame\n",
    "            frame.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        self.show_frame(StartPage)\n",
    "\n",
    "    def show_frame(self, cont):\n",
    "        frame = self.frames[cont]\n",
    "        frame.tkraise()\n",
    "\n",
    "class StartPage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self,parent)\n",
    "        label = tk.Label(self, text=\"Sign Language Translator\", font=(\"Verdana\", 12))\n",
    "        label.pack(pady=10,padx=10)\n",
    "        button_text_to_sign = tk.Button(self, text=\"Text to Sign\", command=lambda: controller.show_frame(VtoS))\n",
    "        button_text_to_sign.pack()\n",
    "        \n",
    "        # New button for camera detection\n",
    "        button_camera_detection = tk.Button(self, text=\"Camera Detection\", command=self.start_camera_detection)\n",
    "        button_camera_detection.pack()\n",
    "\n",
    "    def start_camera_detection(self):\n",
    "        # Execute the code from test.py for camera detection\n",
    "        exec(open(\"test.py\").read())\n",
    "\n",
    "# VtoS class\n",
    "class VtoS(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        cnt=0\n",
    "        gif_frames=[]\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        label = tk.Label(self, text=\"Text to Sign\", font=(\"Verdana\", 12))\n",
    "        label.pack(pady=10,padx=10)\n",
    "        gif_box = tk.Label(self)\n",
    "        \n",
    "        button1 = tk.Button(self, text=\"Back to Home\",command=lambda: controller.show_frame(StartPage))\n",
    "        button1.pack()\n",
    "        \n",
    "        def gif_stream():\n",
    "            global cnt\n",
    "            global gif_frames\n",
    "            if(cnt==len(gif_frames)):\n",
    "                return\n",
    "            img = gif_frames[cnt]\n",
    "            cnt+=1\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            gif_box.imgtk = imgtk\n",
    "            gif_box.configure(image=imgtk)\n",
    "            gif_box.after(50, gif_stream)\n",
    "        \n",
    "        def hear_voice(inputtxt):\n",
    "            store = sr.Recognizer()\n",
    "            with sr.Microphone() as s:\n",
    "                audio_input = store.record(s, duration=10)\n",
    "                try:\n",
    "                    text_output = store.recognize_google(audio_input)\n",
    "                    inputtxt.insert(END, text_output)\n",
    "                    # Automatically convert to sign language after voice detection\n",
    "                    Take_input(inputtxt)\n",
    "                except:\n",
    "                    print(\"Error Hearing Voice\")\n",
    "                    inputtxt.insert(END, '')\n",
    "                    \n",
    "        def Take_input(inputtxt):\n",
    "            INPUT = inputtxt.get(\"1.0\", \"end-1c\")\n",
    "            print(INPUT)\n",
    "            global gif_frames\n",
    "            gif_frames=func(INPUT)\n",
    "            global cnt\n",
    "            cnt=0\n",
    "            gif_stream()\n",
    "            gif_box.place(x=400,y=160)\n",
    "        \n",
    "        l = tk.Label(self,text = \"Enter Text or Voice:\")\n",
    "        l1 = tk.Label(self,text = \"OR\")\n",
    "        inputtxt = tk.Text(self, height = 4,width = 25)\n",
    "        voice_button= tk.Button(self,height = 2,width = 20, text=\"Record Voice\",command=lambda: hear_voice(inputtxt))\n",
    "        voice_button.place(x=50,y=180)\n",
    "        Display = tk.Button(self, height = 2,width = 20,text =\"Convert\",command = lambda:Take_input(inputtxt))\n",
    "        l.place(x=50, y=160)\n",
    "        l1.place(x=115, y=230)\n",
    "        inputtxt.place(x=50, y=250)\n",
    "        Display.pack()\n",
    "\n",
    "app = Tk_Manage()\n",
    "app.geometry(\"800x750\")\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67810af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122bbcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
